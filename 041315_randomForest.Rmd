---
title: "Raondom Forest on the Whole Dataset"
author: "Niel"
date: "April 13, 2015"
output: html_document
---

```{r, echo=F, message=F}
deps = c("pROC","randomForest");
for (dep in deps){
  if (dep %in% installed.packages()[,"Package"] == FALSE){
    install.packages(as.character(dep), quiet=TRUE);
  }
  library(dep, verbose=FALSE, character.only=TRUE)
}

meta <- read.delim('metadata.tsv', header=T, sep='\t')
shared <- read.delim('glne007.final.an.unique_list.0.03.subsample.0.03.filter.shared', header=T, sep='\t')

all.data <- merge(meta, shared, by.x='sample', by.y='Group')

```

Here I'll try running random forest(RF) on the whole dataset.  I've found that removing some of the noise from the dataset can greatly improve RF's results, so I started with a RF model with the 335 most abundant OTUs.  From that model, I took the OTUs with the highest importance and reran RF.  


```{r, warning=F, results='hide', echo=F, fig.width=7, fig.height=7, cache=T}

canc.data <- all.data[all.data$dx!='adenoma',]
canc.data$dx <- factor(canc.data$dx, levels=c('normal', 'cancer'))

canc.rf <- cbind(dx=canc.data$dx, canc.data[,grep('Otu[0123456789]', colnames(all.data))]) 
canc.rf.out <- randomForest(dx ~ ., data=canc.rf, importance=TRUE, ntree=2000)

canc.rf.pred <- predict(canc.rf.out, type='prob')
canc.rf.roc<-roc(canc.data$dx ~ canc.rf.pred[,1], levels=c('normal','cancer'))

canc.imp <- as.data.frame(importance(canc.rf.out, scale=T)) 
canc.imp <- canc.imp[order(canc.imp[,3], decreasing=T),] 
canc.otus <- row.names(canc.imp) 

aucs <- c()
numOTUs <- c(335,200,150,100,50,40,30,20,10,6)
c <- 1
for(i in numOTUs){
  canc.best.rf <- cbind(dx=canc.rf$dx, canc.rf[,canc.otus[1:i]])
  canc.best.out <- randomForest(dx ~ ., data=canc.best.rf, importance=TRUE, ntree=2000)
  canc.best.pred <- predict(canc.best.out, type='prob')
  aucs[c] <- roc(canc.data$dx ~ canc.best.pred[,1], levels=c('normal','cancer'))$auc
  c <- c+1
  cat(i,'otu model done.\n')
  }

plot(numOTUs,aucs, type='b', ylab='AUC', xlab='Number of OTUs in RF model')
```

The plot above shows how the AUC changed with different numbers of OTUs going into RF.  It peaks with ~50 OTUs. I generated ROC curves for the originial 335-OTU RF model, a 50-OTU RF model, the FIT logit model, and a RF model with 50 OTUs + FIT.


```{r, warning=F, results='hide', echo=F, fig.width=7, fig.height=7, cache=T}

canc.best.rf <- cbind(dx=canc.rf$dx, canc.rf[,canc.otus[1:50]])
canc.best.out <- randomForest(dx ~ ., data=canc.best.rf, importance=TRUE, ntree=2000)
canc.best.pred <- predict(canc.best.out, type='prob')
canc.best.roc <- roc(canc.data$dx ~ canc.best.pred[,1], levels=c('normal','cancer'))

canc.fit.rf <- cbind(canc.best.rf, fit=canc.data$fit_result)
canc.fit.out <- randomForest(dx ~ ., data=canc.fit.rf, importance=TRUE, ntree=2000)
canc.fit.pred <- predict(canc.fit.out, type='prob')
canc.fit.roc <- roc(canc.data$dx ~ canc.fit.pred[,1], levels=c('normal','cancer'))

fit <- glm(dx ~ fit_result,  data=canc.data, family=binomial('logit'))
canc.data$fit.prob=predict(fit, type=c("response"))
fit.roc <- roc(dx ~ fit.prob, data = canc.data)

plot(c(1,0),c(0,1), type='l', lty=2, xlim=c(1.01,0), ylim=c(-0.01,1.01), xaxs='i', yaxs='i', ylab='Sensitivity', xlab='Specificity', main='Normal vs. Carcinoma: Whole Dataset')
plot(canc.rf.roc, col='red', lwd=2, add=T)
plot(canc.best.roc, col='orange', lwd=2, add=T)
plot(canc.fit.roc, col='green4', lwd=2, add=T)
plot(fit.roc, col='blue', lwd=2, add=T)
legend('bottomright', legend=c(sprintf('335-OTU RF: %.3g',canc.rf.roc$auc),
                               sprintf('50-OTU RF: %.3g',canc.best.roc$auc),
                               sprintf('FIT: %.3g',fit.roc$auc),
                               sprintf('50-OTU RF + FIT: %.3g',canc.fit.roc$auc)),
                               lty=1, lwd=2, col=c('red','orange','blue','green4'))
```

The RF models for Normal vs Carcinoma are good (a little better than what I got from the logit models), but not as good as FIT. Combining RF and FIT is a little better than FIT alone (p=`r signif(roc.test(fit.roc, canc.fit.roc)$p.value, 3)`).  

```{r, warning=F, results='hide', echo=F, fig.width=7, fig.height=7, cache=T}

#Adenoma vs Normal
ade.data <- all.data[all.data$dx!='cancer',]
ade.data$dx <- factor(ade.data$dx, levels=c('normal', 'adenoma'))

ade.rf <- cbind(dx=ade.data$dx, ade.data[,grep('Otu[0123456789]', colnames(all.data))]) 
ade.rf.out <- randomForest(dx ~ ., data=ade.rf, importance=TRUE, ntree=2000)

ade.rf.pred <- predict(ade.rf.out, type='prob')
ade.rf.roc<-roc(ade.data$dx ~ ade.rf.pred[,1], levels=c('normal','adenoma'))

ade.imp <- as.data.frame(importance(ade.rf.out, scale=T)) 
ade.imp <- ade.imp[order(ade.imp[,3], decreasing=T),] 
ade.otus <- row.names(ade.imp) 

aucs <- c()
numOTUs <- c(335,200,150,100,50,40,30,20,10,6)
c <- 1
for(i in numOTUs){
  ade.best.rf <- cbind(dx=ade.rf$dx, ade.rf[,ade.otus[1:i]])
  ade.best.out <- randomForest(dx ~ ., data=ade.best.rf, importance=TRUE, ntree=2000)
  ade.best.pred <- predict(ade.best.out, type='prob')
  aucs[c] <- roc(ade.data$dx ~ ade.best.pred[,1], levels=c('normal','adenoma'))$auc
  c <- c+1
  cat(i,'otu model done.\n')
  }

plot(numOTUs,aucs, type='b', ylab='AUC', xlab='Number of OTUs in RF model')
```

For Normal vs Adenoma, the results vary, but RF usually does best with about 40-50 OTUs.

```{r, warning=F, results='hide', echo=F, fig.width=7, fig.height=7, cache=T}

ade.best.rf <- cbind(dx=ade.rf$dx, ade.rf[,ade.otus[1:40]])
ade.best.out <- randomForest(dx ~ ., data=ade.best.rf, importance=TRUE, ntree=2000)
ade.best.pred <- predict(ade.best.out, type='prob')
ade.best.roc <- roc(ade.data$dx ~ ade.best.pred[,1], levels=c('normal','adenoma'))

ade.fit.rf <- cbind(ade.best.rf, fit=ade.data$fit_result)
ade.fit.out <- randomForest(dx ~ ., data=ade.fit.rf, importance=TRUE, ntree=2000)
ade.fit.pred <- predict(ade.fit.out, type='prob')
ade.fit.roc <- roc(ade.data$dx ~ ade.fit.pred[,1], levels=c('normal','adenoma'))

fit <- glm(dx ~ fit_result,  data=ade.data, family=binomial('logit'))
ade.data$fit.prob=predict(fit, type=c("response"))
fit.roc <- roc(dx ~ fit.prob, data = ade.data)

plot(c(1,0),c(0,1), type='l', lty=2, xlim=c(1.01,0), ylim=c(-0.01,1.01), xaxs='i', yaxs='i', ylab='Sensitivity', xlab='Specificity', main='Normal vs. Adenoma: Whole Dataset')
plot(ade.rf.roc, col='red', lwd=2, add=T)
plot(ade.best.roc, col='orange', lwd=2, add=T)
plot(ade.fit.roc, col='green4', lwd=2, add=T)
plot(fit.roc, col='blue', lwd=2, add=T)
legend('bottomright', legend=c(sprintf('335-OTU RF: %.3g',ade.rf.roc$auc),
                               sprintf('40-OTU RF: %.3g',ade.best.roc$auc),
                               sprintf('FIT: %.3g',fit.roc$auc),
                               sprintf('40-OTU RF + FIT: %.3g',ade.fit.roc$auc)),
                               lty=1, lwd=2, col=c('red','orange','blue','green4'))
```

RF with 335-OTUs is terrible, but with only 40 OTUs, it's way better than FIT.  Adding FIT to RF further improves the prediction (p=`r signif(roc.test(ade.best.roc,ade.fit.roc)$p.value, 3)`).  


```{r, warning=F, results='hide', echo=F, fig.width=7, fig.height=7, cache=T}

#Lesion vs Normal
les.data <- all.data
levels(les.data$dx)[1:2] <- 'lesion'
les.data$dx <- factor(les.data$dx, levels=c('normal', 'lesion'))

les.rf <- cbind(dx=les.data$dx, les.data[,grep('Otu[0123456789]', colnames(all.data))]) 
les.rf.out <- randomForest(dx ~ ., data=les.rf, importance=TRUE, ntree=2000)

les.rf.pred <- predict(les.rf.out, type='prob')
les.rf.roc<-roc(les.data$dx ~ les.rf.pred[,1], levels=c('normal','lesion'))

les.imp <- as.data.frame(importance(les.rf.out, scale=T)) 
les.imp <- les.imp[order(les.imp[,3], decreasing=T),] 
les.otus <- row.names(les.imp) 

aucs <- c()
numOTUs <- c(335,200,150,100,50,40,30,20,10,6)
c <- 1
for(i in numOTUs){
  les.best.rf <- cbind(dx=les.rf$dx, les.rf[,les.otus[1:i]])
  les.best.out <- randomForest(dx ~ ., data=les.best.rf, importance=TRUE, ntree=2000)
  les.best.pred <- predict(les.best.out, type='prob')
  aucs[c] <- roc(les.data$dx ~ les.best.pred[,1], levels=c('normal','lesion'))$auc
  c <- c+1
  cat(i,'otu model done.\n')
  }

plot(numOTUs,aucs, type='b', ylab='AUC', xlab='Number of OTUs in RF model')
```

For Normal vs Lesion, the RF usually does best with about 30-50 OTUs.

```{r, warning=F, results='hide', echo=F, fig.width=7, fig.height=7, cache=T}

les.best.rf <- cbind(dx=les.rf$dx, les.rf[,les.otus[1:30]])
les.best.out <- randomForest(dx ~ ., data=les.best.rf, importance=TRUE, ntree=2000)
les.best.pred <- predict(les.best.out, type='prob')
les.best.roc <- roc(les.data$dx ~ les.best.pred[,1], levels=c('normal','lesion'))

les.fit.rf <- cbind(les.best.rf, fit=les.data$fit_result)
les.fit.out <- randomForest(dx ~ ., data=les.fit.rf, importance=TRUE, ntree=2000)
les.fit.pred <- predict(les.fit.out, type='prob')
les.fit.roc <- roc(les.data$dx ~ les.fit.pred[,1], levels=c('normal','lesion'))

fit <- glm(dx ~ fit_result,  data=les.data, family=binomial('logit'))
les.data$fit.prob=predict(fit, type=c("response"))
fit.roc <- roc(dx ~ fit.prob, data = les.data)

plot(c(1,0),c(0,1), type='l', lty=2, xlim=c(1.01,0), ylim=c(-0.01,1.01), xaxs='i', yaxs='i', ylab='Sensitivity', xlab='Specificity', main='Normal vs. Lesion: Whole Dataset')
plot(les.rf.roc, col='red', lwd=2, add=T)
plot(les.best.roc, col='orange', lwd=2, add=T)
plot(les.fit.roc, col='green4', lwd=2, add=T)
plot(fit.roc, col='blue', lwd=2, add=T)
legend('bottomright', legend=c(sprintf('335-OTU RF: %.3g',les.rf.roc$auc),
                               sprintf('30-OTU RF: %.3g',les.best.roc$auc),
                               sprintf('FIT: %.3g',fit.roc$auc),
                               sprintf('30-OTU RF + FIT: %.3g',les.fit.roc$auc)),
                               lty=1, lwd=2, col=c('red','orange','blue','green4'))
```

Again RF with 335-OTUs is isn't very good, but with 30 OTUs, it has the same AUC as FIT.  The difference is that RF has better sensitivity and FIT has better specificity. Combining FIT with RF basically gives you the best of both, and it's better than FIT alone (p=`r signif(roc.test(les.fit.roc,fit.roc)$p.value,3)`). 

###Conclusions
RF does pretty well when used on the whole dataset.  It's tempting to move forward with just RF, but we then lose the power/impact of having an independent validation set. However, if I can't come up with logit models for lesion and adenoma that work on the testing set, we may not have a choice.  





